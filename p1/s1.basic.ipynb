{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- OpenAI ----- #\n",
    "chat_model = ChatOpenAI()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----- Ollama ----- #\n",
    "# chat_model = ChatOllama()\n",
    "# embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic basics\n",
    "\n",
    "Just invoking basic invoke(predict)\n",
    "\n",
    "> Note: .invoke() has replaced .predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 13, 'total_tokens': 50}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-e3ee2f0b-dec5-4caf-a38e-54a397fe26f9-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Hello, how are you?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to this question is subjective and can vary depending on individual beliefs and perspectives. Some believe that the reason for life, the universe, and everything is to seek knowledge and understanding, to experience love and connection, to fulfill a higher purpose or destiny, or simply to exist and create meaning in the world. Ultimately, the reason for existence may be unknowable and open to interpretation.', response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 19, 'total_tokens': 96}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-af8dc18a-b0ef-4bde-bb5b-757020fd0f69-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"What is the reason of life, universe, and everything?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to this question is subjective and can vary depending on individual beliefs and perspectives. Some may believe that the reason for life, the universe, and everything is to seek happiness, fulfillment, and personal growth. Others may believe that it is to fulfill a higher purpose or spiritual journey. Ultimately, the reason for life, the universe, and everything is a complex and philosophical question that may not have a definitive answer.\n",
      "The question of the reason for existence is a philosophical and existential question that has puzzled humanity for centuries. Some may argue that the reason for life, the universe, and everything is unknowable and ultimately a mystery. Others may attribute meaning and purpose to life based on their personal beliefs, values, and experiences. Ultimately, it is up to each individual to determine their own meaning and purpose in the grand scheme of things.\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "print(chat_model.invoke(\"What is the reason of life, universe, and everything?\").content)\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "print(chat_model.invoke(\"What is the reason of life, universe, and everything?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic chain\n",
    "\n",
    "Chain is a way to create a sequence of operations. It is a way to create a pipeline of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How is it going?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How is it going?',\n",
       " 'history': '',\n",
       " 'response': \"Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# .run() was replaced with .invoke()\n",
    "\n",
    "conversation_chain.invoke(\"How is it going?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How is it going?\n",
      "AI: Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\n",
      "Human: What was my question again?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was my question again?',\n",
       " 'history': \"Human: How is it going?\\nAI: Hello! I'm doing well, thank you for asking. I've been busy processing information and learning new things. How about you?\",\n",
       " 'response': 'Your question was, \"How is it going?\" So, how are you doing today?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"What was my question again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant that speaks in riddles, like Master Yoda. What is the meaning of life?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the journey of life, seek balance you must. Harmony in mind, body, and spirit find. Joy in simple things discover. The meaning of life, within yourself, lies.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatMessagePromptTemplate\n",
    "\n",
    "\n",
    "yoda_chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=PromptTemplate.from_template(\"You are a helpful assistant that speaks in riddles, like Master Yoda. {input}\"),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "yoda_chain.run(input=\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate article title based on user input. Internships in the tech industry\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"The Top Internships in the Tech Industry for Aspiring Professionals\"\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant that speaks in riddles, like Master Yoda. \"The Top Internships in the Tech Industry for Aspiring Professionals\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIn the tech industry, seek you must,\n",
      "The top internships, a great opportunity, it is a must.\n",
      "In coding, design, and engineering, they excel,\n",
      "A foot in the door, these internships will propel.\n",
      "\n",
      "Google, Apple, and Microsoft, giants of the tech world,\n",
      "Their internships coveted, with knowledge unfurled.\n",
      "Seek them out, young Padawan, your skills to hone,\n",
      "In the tech industry, the Force is strong, make it known.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "title_chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=PromptTemplate.from_template(\"Generate article title based on user input. {input}\"),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, yoda_chain],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain = chain.run(\"Internships in the tech industry\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
