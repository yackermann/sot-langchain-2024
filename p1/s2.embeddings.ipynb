{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings \n",
    "\n",
    "# ----- OpenAI ----- #\n",
    "chat_model = ChatOpenAI()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----- Ollama ----- #\n",
    "# chat_model = ChatOllama()\n",
    "# embeddings = OllamaEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.015847994027185078,\n",
       " 0.0009191049037337303,\n",
       " -0.017371082692209036,\n",
       " -0.020220307649311424,\n",
       " -0.01355023217530438,\n",
       " 0.01916990244418255,\n",
       " -0.00871836674159544,\n",
       " 0.0026194490513110906,\n",
       " -0.01183675882413629,\n",
       " -0.005061642270822813,\n",
       " 0.04283028844414264,\n",
       " -0.0014049175672195427,\n",
       " -0.00828507450134752,\n",
       " 0.008895622573394808,\n",
       " 0.009105703800685098,\n",
       " -0.01717413218190866,\n",
       " 0.02593188921182869,\n",
       " -0.01320885029737298,\n",
       " 0.03466338667041404,\n",
       " 0.00012350472398580517,\n",
       " -0.0037256574753406595,\n",
       " -0.024947132935036507,\n",
       " 0.003394123169490408,\n",
       " -0.0031446518867061716,\n",
       " -0.0016954203615367866,\n",
       " -0.016622668145364394,\n",
       " 0.008094687952558239,\n",
       " -0.018053846448071835,\n",
       " 0.015585393657225435,\n",
       " -0.02833469214301582,\n",
       " 0.008403245366321291,\n",
       " -0.010142979220146633,\n",
       " -0.038287285745695745,\n",
       " -0.024763312210403468,\n",
       " -0.007753306540288127,\n",
       " -0.02616823094177623,\n",
       " -0.01167263277800426,\n",
       " -0.0008912035271140268,\n",
       " 0.012394785890869073,\n",
       " -0.01918303222984989,\n",
       " 0.017712464570140436,\n",
       " 0.0012982357303659806,\n",
       " 0.008094687952558239,\n",
       " -0.00693924213378422,\n",
       " -0.023371525127343196,\n",
       " 0.008193164139031003,\n",
       " -0.007753306540288127,\n",
       " -0.025262255241633228,\n",
       " -0.006834201520139075,\n",
       " 0.03658037635603875,\n",
       " 0.021900957467633743,\n",
       " -0.0011218003937554985,\n",
       " -0.033612981465285165,\n",
       " -0.019314333811813574,\n",
       " -0.01303815935840728,\n",
       " 0.001772559482146906,\n",
       " -0.009919768207189004,\n",
       " 0.023450305703992376,\n",
       " 0.012204400273402366,\n",
       " -0.027205506361237766,\n",
       " -0.0013327021162346752,\n",
       " 0.011101474062958989,\n",
       " -0.018959822148214834,\n",
       " 0.02833469214301582,\n",
       " -0.0054653915619966445,\n",
       " -0.00900722854553491,\n",
       " 0.018053846448071835,\n",
       " -0.003715809903259512,\n",
       " -0.031223306457120223,\n",
       " 0.017646813779158593,\n",
       " 0.011357510471407537,\n",
       " 0.007116497965583589,\n",
       " -0.008271944715680183,\n",
       " -0.020535429955908145,\n",
       " -0.0010331723614404923,\n",
       " -0.0026309378466006558,\n",
       " -0.015874255461164905,\n",
       " 0.00572799332894015,\n",
       " -0.019445633531132107,\n",
       " -0.033219076719394114,\n",
       " 0.018474008902652415,\n",
       " -0.025800587629865004,\n",
       " -0.0033186252720887057,\n",
       " 0.022662501800145722,\n",
       " 0.024461321552119237,\n",
       " 0.00019397627344832274,\n",
       " 0.011357510471407537,\n",
       " 0.03379680218991821,\n",
       " -0.0266540423246935,\n",
       " -0.0221766885545833,\n",
       " 0.0027786511949872256,\n",
       " 0.010930783123993289,\n",
       " 0.0072149736863950644,\n",
       " 0.01416734607150791,\n",
       " -0.026877254268973704,\n",
       " 0.01941937395979743,\n",
       " 0.006489537195790841,\n",
       " 0.024947132935036507,\n",
       " -0.0004456017635570134,\n",
       " -0.01767307521313842,\n",
       " -0.011186819532441838,\n",
       " -0.0039423038282952625,\n",
       " -0.004779345359717011,\n",
       " -0.010806048297508425,\n",
       " -0.013044725182563525,\n",
       " 0.004700565248729118,\n",
       " 1.118107503293365e-05,\n",
       " -0.0047136950343964566,\n",
       " 0.01916990244418255,\n",
       " 0.009086008190861515,\n",
       " -0.011849888609803629,\n",
       " 0.018565919264968932,\n",
       " 0.003919325772054845,\n",
       " -0.010550011889059874,\n",
       " 0.0034400783506486673,\n",
       " 0.007398794411028102,\n",
       " -0.002460246907634956,\n",
       " 0.004920493815269912,\n",
       " -0.011810498321479039,\n",
       " -0.025380425175284424,\n",
       " 0.01800132544275733,\n",
       " 0.0011751413121822796,\n",
       " 0.006893286952625961,\n",
       " -0.014311776507816358,\n",
       " 0.0017742007053553233,\n",
       " -0.020036486924678385,\n",
       " -0.017082221819592142,\n",
       " -0.017266042544225178,\n",
       " -0.0156510435168847,\n",
       " -0.01395726484421762,\n",
       " 0.022465549427200193,\n",
       " -0.018526529907966917,\n",
       " -0.023647256214292752,\n",
       " -0.002726130888164653,\n",
       " -0.009368305101967317,\n",
       " 0.016425717635064018,\n",
       " -0.022557461652161864,\n",
       " 0.018093237667719,\n",
       " -0.01825079695837221,\n",
       " -0.012440742003349908,\n",
       " -0.006453429353883086,\n",
       " 0.01832957753502139,\n",
       " 0.0024454756659285566,\n",
       " -0.0014771329017890884,\n",
       " -0.0031512167795398408,\n",
       " 0.01932746359748091,\n",
       " 0.0072346688305573595,\n",
       " -0.013176025833204635,\n",
       " 0.00391604332563801,\n",
       " -0.02201912740128494,\n",
       " 0.0032053783095708304,\n",
       " -0.00205485592759142,\n",
       " 0.007628570782480687,\n",
       " 0.003226714676941543,\n",
       " 0.021861566247986578,\n",
       " 0.023082664254726302,\n",
       " 0.010379320950094174,\n",
       " 0.009223874665658868,\n",
       " -0.017961936085755314,\n",
       " -0.006299151112662847,\n",
       " -0.021480795013053163,\n",
       " -0.01683275030397726,\n",
       " 0.012558911937001102,\n",
       " -0.009893507704531753,\n",
       " 0.0008903829155098182,\n",
       " 0.025039043297353025,\n",
       " 0.01777811536112228,\n",
       " 0.01968197526107965,\n",
       " -0.010550011889059874,\n",
       " 0.0044379639474469,\n",
       " -0.015966165823481426,\n",
       " -0.01133781579290653,\n",
       " -0.03017290125199135,\n",
       " 0.005954486788314613,\n",
       " -0.021533316018367665,\n",
       " -0.013274501088354823,\n",
       " 0.005796926100677539,\n",
       " -0.00027839851122069204,\n",
       " -0.010254585192286735,\n",
       " -0.001230123453817478,\n",
       " -0.04409077767052953,\n",
       " 0.017476122840192895,\n",
       " 0.028544772438983537,\n",
       " 0.03303525599476108,\n",
       " 0.007969953126073374,\n",
       " -0.0011579081192479323,\n",
       " 0.007681091322133904,\n",
       " 0.0018447748167164518,\n",
       " 0.020377868802609785,\n",
       " -0.022898841667448114,\n",
       " 0.0026063190328131087,\n",
       " 0.035057287691014793,\n",
       " 0.0092173097728252,\n",
       " -0.016977181671608284,\n",
       " -0.6781418924939606,\n",
       " -0.03067184428322111,\n",
       " 0.01366840304027815,\n",
       " -0.007818956865608682,\n",
       " 0.023069532606413812,\n",
       " 0.013602753180618883,\n",
       " 0.014758198533731615,\n",
       " 0.014351166796140949,\n",
       " -0.03229997309622892,\n",
       " 0.022951362672762616,\n",
       " -0.023634126428625415,\n",
       " 0.024133069459855175,\n",
       " -0.006568317772440022,\n",
       " 0.003165988254076884,\n",
       " 0.003308777700007558,\n",
       " -0.008363855077996701,\n",
       " 0.0026227314977279254,\n",
       " 0.013760313402594669,\n",
       " 0.0016067923292217804,\n",
       " 0.006105482583118017,\n",
       " -0.04086077961584858,\n",
       " 0.009447085678616497,\n",
       " -0.027152985355923264,\n",
       " 0.027573147810503844,\n",
       " 0.029700219654741417,\n",
       " -0.007320014300040209,\n",
       " 0.008784016601254706,\n",
       " -0.012558911937001102,\n",
       " -0.017423603697523538,\n",
       " 0.021927217038968418,\n",
       " -0.008383549756497709,\n",
       " 0.00012124799114252808,\n",
       " 0.01832957753502139,\n",
       " 0.008803712211078289,\n",
       " 0.05519881476367704,\n",
       " -0.008849667392236549,\n",
       " 0.006308998917574638,\n",
       " 0.021559575589702343,\n",
       " 0.012519521648676512,\n",
       " 0.05062955249389547,\n",
       " -0.027573147810503844,\n",
       " -0.02173026652866804,\n",
       " 0.01146911644354764,\n",
       " -0.0234240461326577,\n",
       " 0.010530316279236292,\n",
       " -0.008948142647386737,\n",
       " 0.005173247777301627,\n",
       " -0.007930562837748784,\n",
       " -0.012250355454560624,\n",
       " -0.0010331723614404923,\n",
       " 0.010550011889059874,\n",
       " 0.0007648266043058304,\n",
       " -0.011987754153278407,\n",
       " 0.017581164850821902,\n",
       " -0.0005260234469992894,\n",
       " -0.0024438344427201394,\n",
       " 0.022636240366165895,\n",
       " -0.007536660420164168,\n",
       " 0.00568860304061556,\n",
       " 0.012230660776059618,\n",
       " -0.005708298184777855,\n",
       " 0.01416734607150791,\n",
       " -0.020981851981823403,\n",
       " 0.001314648311696119,\n",
       " -0.006932677240950551,\n",
       " 0.0074381846993526925,\n",
       " -0.01374718361692733,\n",
       " -0.004861408382783027,\n",
       " -0.005196225367880757,\n",
       " -0.01617624611944914,\n",
       " -0.000519048073740533,\n",
       " 0.008580501198120661,\n",
       " -0.0082522491058566,\n",
       " -0.003489316211054405,\n",
       " 0.009164788767510696,\n",
       " 0.020128397286994906,\n",
       " 0.01825079695837221,\n",
       " -0.016451977206398696,\n",
       " -0.006161285569188068,\n",
       " 0.0044379639474469,\n",
       " 1.2565887128360918e-05,\n",
       " 0.018368968754668556,\n",
       " -0.011902408683795556,\n",
       " -0.0373156592545709,\n",
       " 0.027940789259769918,\n",
       " -0.026404570809078622,\n",
       " -0.021008111553158078,\n",
       " 0.004477353770110203,\n",
       " 0.011357510471407537,\n",
       " 0.034689646241748716,\n",
       " 0.014022914703876888,\n",
       " 0.027730708963802204,\n",
       " 0.014561248023431238,\n",
       " -0.014836979110380795,\n",
       " 0.026102580150794388,\n",
       " 0.013734053831259993,\n",
       " -0.0017709182589384887,\n",
       " 0.011620111772689757,\n",
       " 0.009965723388347265,\n",
       " -0.006660228134756541,\n",
       " 0.017620554207823914,\n",
       " 0.008449200547479552,\n",
       " 0.012572042653991016,\n",
       " 0.004254142757152575,\n",
       " 0.014836979110380795,\n",
       " 0.019314333811813574,\n",
       " -0.013760313402594669,\n",
       " 0.012913424531922416,\n",
       " 0.025498596971580773,\n",
       " -0.04170110452500974,\n",
       " 0.022373639064883676,\n",
       " 0.019944576562361867,\n",
       " -0.02635205166640927,\n",
       " 0.004418268803284605,\n",
       " 0.016386328278062006,\n",
       " -0.032615095402825645,\n",
       " 0.004822018094458437,\n",
       " 0.01649136842604586,\n",
       " 0.020220307649311424,\n",
       " -0.02057481931291016,\n",
       " 0.010943913840983203,\n",
       " 0.009552125826600354,\n",
       " 0.005567149729224954,\n",
       " 0.013438627134486852,\n",
       " -0.0002599343717762013,\n",
       " 0.043801914935267486,\n",
       " -0.009013793438368578,\n",
       " -0.007818956865608682,\n",
       " -0.03056680413523725,\n",
       " -0.0017561469008167674,\n",
       " 0.010097024038988373,\n",
       " -0.02851851286764886,\n",
       " 0.0014590790972505326,\n",
       " -0.021100023778119748,\n",
       " 0.011876148181138305,\n",
       " -0.01717413218190866,\n",
       " 0.02534103581828241,\n",
       " -0.003476186192556423,\n",
       " 0.03894378993022387,\n",
       " 0.00804873277139998,\n",
       " -0.01183675882413629,\n",
       " 0.014928889472697314,\n",
       " 0.003047817621933757,\n",
       " -0.011232774713600097,\n",
       " 0.009053183726693169,\n",
       " -0.025813717415532345,\n",
       " 0.002176309238982025,\n",
       " 0.002150048969155417,\n",
       " 0.0001997206856450204,\n",
       " 0.007241233723391029,\n",
       " 0.008101253776714484,\n",
       " 0.002632579069809073,\n",
       " -0.009328914813642725,\n",
       " -0.009578386329257605,\n",
       " 0.002305968666414717,\n",
       " -0.012375091212368065,\n",
       " -0.020496040598906133,\n",
       " -0.004887668885440279,\n",
       " -0.022688761371480397,\n",
       " -0.020561689527242823,\n",
       " -0.0012342266282538432,\n",
       " 0.01767307521313842,\n",
       " 0.0012514598211881905,\n",
       " 0.01120651514226542,\n",
       " -0.008672411560437179,\n",
       " -0.023187704402710157,\n",
       " -0.017896285294773474,\n",
       " 0.007622005889647018,\n",
       " 0.006249913485087753,\n",
       " -0.02401489766355883,\n",
       " 0.019944576562361867,\n",
       " -0.01303815935840728,\n",
       " -0.0068604615571350395,\n",
       " 0.0024881484006699815,\n",
       " 0.010169239722803885,\n",
       " -0.003666572042853774,\n",
       " -0.007923997013592539,\n",
       " -0.005780513402932079,\n",
       " -0.0004105198607775014,\n",
       " -0.0061481553178594425,\n",
       " 0.002762238497241765,\n",
       " -0.0024897896238783987,\n",
       " -0.0021155825832867223,\n",
       " 0.02008900792999289,\n",
       " 0.04984174672740366,\n",
       " 0.002525897232955511,\n",
       " 0.012926554317589755,\n",
       " 0.022898841667448114,\n",
       " -0.0052618756932013115,\n",
       " -0.0011332891890450635,\n",
       " 0.04500988129369472,\n",
       " 0.00012124799114252808,\n",
       " -0.01070757211103566,\n",
       " 0.0016149986780945105,\n",
       " 0.006112047941612974,\n",
       " -0.0008739702759720186,\n",
       " -0.008029038092898972,\n",
       " 0.0110029988078088,\n",
       " 0.01865782962728545,\n",
       " 0.0173579529065417,\n",
       " 0.032693874116829676,\n",
       " -0.0004123662659908013,\n",
       " 0.02561676690523197,\n",
       " -0.022767541948129577,\n",
       " -0.025065304731332852,\n",
       " -0.019550675541761115,\n",
       " 0.018145756810388353,\n",
       " -0.0269954242026249,\n",
       " 0.017161002396241323,\n",
       " 0.007057412998757991,\n",
       " 0.007372534374032138,\n",
       " -0.01743673348319088,\n",
       " -0.010090459146154704,\n",
       " 0.030619323277906608,\n",
       " 0.0029411357850801945,\n",
       " 0.0145481182377639,\n",
       " -0.0036764196149349213,\n",
       " 0.00535378605551783,\n",
       " -0.011108039887115232,\n",
       " -0.0014853392506618188,\n",
       " -2.764495186429296e-05,\n",
       " -0.016044946400130607,\n",
       " -0.032536312963531315,\n",
       " -0.033376637872692475,\n",
       " -0.0037584826380009364,\n",
       " 0.013313891376679413,\n",
       " 0.005655777645124639,\n",
       " 0.01183675882413629,\n",
       " -0.007123063324078546,\n",
       " -0.010346495554603255,\n",
       " -0.03434826436381732,\n",
       " 0.014797588822056205,\n",
       " 0.017449863268858216,\n",
       " 0.025708677267548486,\n",
       " 0.010412145414262521,\n",
       " -0.00818003342204109,\n",
       " 0.0059938770766392035,\n",
       " -0.00019018085746736632,\n",
       " 0.02914875561819715,\n",
       " 0.004309945743222626,\n",
       " -0.015375312429935145,\n",
       " 0.01175797824748711,\n",
       " 0.031853549207668516,\n",
       " -0.03327159958735377,\n",
       " 0.016793359084330096,\n",
       " 0.01685900987531194,\n",
       " 0.010733832613692913,\n",
       " -0.014784459036388866,\n",
       " 0.014324906293483696,\n",
       " 0.018066976233739172,\n",
       " -0.015375312429935145,\n",
       " -0.016662059365011563,\n",
       " -0.008317899896838442,\n",
       " -0.011633242489679669,\n",
       " 0.019773885623396166,\n",
       " -0.0055113472088161915,\n",
       " -0.015047060337671085,\n",
       " 0.004546287007508879,\n",
       " 0.008843102499402879,\n",
       " 0.03426948192452299,\n",
       " 0.023279614765026678,\n",
       " 0.019721366480726813,\n",
       " -0.006233500787342292,\n",
       " 8.303743386239437e-05,\n",
       " -0.0008518132969970975,\n",
       " -0.0002798346106318877,\n",
       " 0.0002050547629357833,\n",
       " -0.009131964303342349,\n",
       " 0.004369030710048224,\n",
       " 0.0001396095759643656,\n",
       " -0.021126283349454426,\n",
       " 0.009795032449381565,\n",
       " 0.015033930552003746,\n",
       " 0.006197392945434537,\n",
       " 0.02123132349743828,\n",
       " 0.01150194183903856,\n",
       " 0.003623899308112349,\n",
       " 0.004815453201624767,\n",
       " -0.011068649598790642,\n",
       " -0.005977464378893743,\n",
       " -0.004093299623098666,\n",
       " -0.037446960836534586,\n",
       " 0.008987532935711327,\n",
       " -0.0076679610708052775,\n",
       " 0.004802323415957429,\n",
       " 0.008022473200065303,\n",
       " -0.025800587629865004,\n",
       " -0.0008690465481391058,\n",
       " -0.026890384054641045,\n",
       " 0.01183675882413629,\n",
       " 0.007451314950681319,\n",
       " 0.00284430152030778,\n",
       " -0.010609096855885472,\n",
       " -0.006246631038670918,\n",
       " 0.006972067529275141,\n",
       " -0.01934059338314825,\n",
       " 0.03608143332480899,\n",
       " 0.010044503964996445,\n",
       " 0.020548559741575486,\n",
       " 0.012224095883225948,\n",
       " -0.0021697441133177123,\n",
       " 0.009571821436423936,\n",
       " -0.010103588931822043,\n",
       " -0.02417245881685719,\n",
       " 0.011147429244117248,\n",
       " 0.016740839941660743,\n",
       " -0.0016191017361155539,\n",
       " -0.014101695280526069,\n",
       " -0.0036764196149349213,\n",
       " 0.0005609001968777493,\n",
       " 0.009506170645442095,\n",
       " -0.004621784672079938,\n",
       " -0.027730708963802204,\n",
       " 0.0077926968286127175,\n",
       " 0.009000662721378665,\n",
       " 0.008659281774769842,\n",
       " -0.01175797824748711,\n",
       " -0.0020105419696415773,\n",
       " 0.036816716223341144,\n",
       " -0.024185588602524528,\n",
       " -0.020207177863644087,\n",
       " -0.006144872871442608,\n",
       " -0.015742953879201223,\n",
       " 0.00022033898875821982,\n",
       " 0.08271944529415667,\n",
       " 0.003315342825671871,\n",
       " 0.01107521449162431,\n",
       " 0.015309661638953304,\n",
       " -0.014640028600080419,\n",
       " 0.004700565248729118,\n",
       " -0.022465549427200193,\n",
       " -0.02341091448434521,\n",
       " -0.01355023217530438,\n",
       " -0.028886154316914936,\n",
       " -0.010766658009183833,\n",
       " -0.012040274227270335,\n",
       " -0.02024656908329125,\n",
       " 0.0004080579677572145,\n",
       " 0.0011053878124253598,\n",
       " 0.0076679610708052775,\n",
       " 0.025984408354498043,\n",
       " 0.0020023356207688474,\n",
       " 0.0011915538935124183,\n",
       " 0.005783795849348914,\n",
       " -0.0008944860317385224,\n",
       " 0.00841637515198863,\n",
       " -0.0090466188338595,\n",
       " 0.02241303028453084,\n",
       " 0.020482908950593643,\n",
       " 0.00031081336807886503,\n",
       " 0.004772780466883343,\n",
       " 0.01625502669609832,\n",
       " -0.0075629204571601326,\n",
       " -0.004677587658149989,\n",
       " 0.00040867342646037095,\n",
       " 0.00841637515198863,\n",
       " 0.0026736105813420807,\n",
       " -0.0028738442365512226,\n",
       " 0.0234240461326577,\n",
       " 0.014574377809098576,\n",
       " -0.014101695280526069,\n",
       " 0.03387558090392224,\n",
       " 0.00036456462141158094,\n",
       " -0.010379320950094174,\n",
       " 0.030461762124608244,\n",
       " 0.014036045420866802,\n",
       " 0.0020203895417227253,\n",
       " 0.005964334593226405,\n",
       " 0.019603194684430468,\n",
       " 0.006381214135728862,\n",
       " 0.010123284541645626,\n",
       " 0.01932746359748091,\n",
       " -0.012486697184508167,\n",
       " -0.010202064186972231,\n",
       " 0.028781114168931077,\n",
       " 0.01865782962728545,\n",
       " 8.519159025514541e-05,\n",
       " -0.007162453146741848,\n",
       " -0.01641258784939668,\n",
       " 0.00419505732466569,\n",
       " 0.007293754263044245,\n",
       " -0.02001022735334371,\n",
       " -0.011922103362296564,\n",
       " -0.01108834427729165,\n",
       " -0.014902629901362638,\n",
       " -0.015375312429935145,\n",
       " -0.0011907332819082097,\n",
       " -0.0166751891506789,\n",
       " -0.031695988054370156,\n",
       " -0.03954777124679233,\n",
       " -0.016872139660979276,\n",
       " -0.016031816614463266,\n",
       " -0.0031824007189917005,\n",
       " 0.008061863488389893,\n",
       " 0.0014073794020321687,\n",
       " -0.0036797022941823998,\n",
       " -0.021690875309020877,\n",
       " -0.010609096855885472,\n",
       " 0.008186599246197333,\n",
       " 0.010149544112980302,\n",
       " -0.00727405911888195,\n",
       " -0.02534103581828241,\n",
       " 0.010714137003869329,\n",
       " 0.01892043092856767,\n",
       " -0.015033930552003746,\n",
       " -0.018145756810388353,\n",
       " 0.01943250374546477,\n",
       " -0.01699031145727562,\n",
       " 0.0005104314772733594,\n",
       " 0.00808812305972457,\n",
       " 0.016136856762447124,\n",
       " -0.005120727237648411,\n",
       " -0.001381939860225091,\n",
       " 0.023213963974044835,\n",
       " 0.03503102811968012,\n",
       " 0.017213521538910675,\n",
       " 0.019642585904077633,\n",
       " -0.01993144677669453,\n",
       " -0.0027720860693229124,\n",
       " 0.015086450625995675,\n",
       " 0.0020827574206264453,\n",
       " 0.00043124074034122685,\n",
       " -0.011324686007239192,\n",
       " 0.01693779045196112,\n",
       " -0.00274254335307947,\n",
       " -0.02891241388824961,\n",
       " 0.0007529274450065003,\n",
       " -0.018565919264968932,\n",
       " 0.012355396533867058,\n",
       " 0.018132627024721015,\n",
       " 0.019865795985712687,\n",
       " -0.006591295363019152,\n",
       " -0.003650159577938957,\n",
       " 0.008895622573394808,\n",
       " 0.023975508306556814,\n",
       " -0.032483793820861966,\n",
       " 0.014036045420866802,\n",
       " -0.02967395822076159,\n",
       " -0.009978853174014602,\n",
       " 0.010753527292193919,\n",
       " 0.018316447749354054,\n",
       " 0.02925379576618101,\n",
       " -0.0068604615571350395,\n",
       " -0.014101695280526069,\n",
       " -0.001024966128983084,\n",
       " -0.03823476287773609,\n",
       " 0.01759429463648924,\n",
       " -0.00419505732466569,\n",
       " 0.005117444791231576,\n",
       " -0.004844996150698853,\n",
       " 0.008882492787727469,\n",
       " -0.02484209278705265,\n",
       " 0.0032480510443122553,\n",
       " -0.010891392835668699,\n",
       " 0.006151437764276277,\n",
       " 0.015874255461164905,\n",
       " -0.024566361700103092,\n",
       " -0.028045829407753776,\n",
       " -0.011357510471407537,\n",
       " -0.009650602013073117,\n",
       " -0.01425925643382443,\n",
       " 0.026470221600060465,\n",
       " -0.010018243462339193,\n",
       " -0.01583486424151774,\n",
       " -0.03411192077122463,\n",
       " 0.00469400035589545,\n",
       " -0.015690434736531866,\n",
       " -0.03356045859732552,\n",
       " -0.03918012979752626,\n",
       " -0.036291513620776705,\n",
       " -0.009847552523373493,\n",
       " 0.005892118909410893,\n",
       " -0.015493483294908916,\n",
       " 0.003067512766096052,\n",
       " 0.01337297634350501,\n",
       " 0.014075435709191392,\n",
       " -0.017502384274172722,\n",
       " 0.0015074962296367398,\n",
       " 0.004244295417902071,\n",
       " -0.030382983410604216,\n",
       " -0.00456926459808801,\n",
       " 0.004135972357840092,\n",
       " 0.023555345851976234,\n",
       " 0.02058795096122265,\n",
       " 0.03542492914028087,\n",
       " 0.006893286952625961,\n",
       " 0.02485522257271999,\n",
       " -0.011817063214312707,\n",
       " 0.003715809903259512,\n",
       " -0.01370779332860274,\n",
       " -0.009493040859774756,\n",
       " -0.012979074391581682,\n",
       " -0.013432062241653183,\n",
       " 0.004989426587007301,\n",
       " 0.01691153088062644,\n",
       " 0.017607424422156577,\n",
       " 0.005573714622058624,\n",
       " 0.003092131579883599,\n",
       " -0.0013015181767828152,\n",
       " -0.004047343976279119,\n",
       " -0.016123726976779787,\n",
       " -0.003935738469800306,\n",
       " -0.006144872871442608,\n",
       " -0.017371082692209036,\n",
       " -0.001982640709437196,\n",
       " -0.016241896910430983,\n",
       " -0.012151880199410436,\n",
       " 0.013786573905251922,\n",
       " 0.0033530916579574003,\n",
       " -0.010346495554603255,\n",
       " 0.012453871789017246,\n",
       " 0.012729602875966802,\n",
       " 0.007077107677258998,\n",
       " 0.006167850462021738,\n",
       " 0.029463877924793876,\n",
       " -0.009276394739650798,\n",
       " 0.006131742620113982,\n",
       " -7.426695816751637e-05,\n",
       " 0.021848436462319237,\n",
       " -0.01104238909613339,\n",
       " 0.01175797824748711,\n",
       " -0.009840987630539824,\n",
       " 0.029227536194846332,\n",
       " 0.015703564522199207,\n",
       " 0.018631570055950775,\n",
       " 0.011272165001924687,\n",
       " 0.00209424621591601,\n",
       " 0.016386328278062006,\n",
       " -0.016950920237628456,\n",
       " 0.017699334784473098,\n",
       " -0.005829751030507173,\n",
       " -0.009479911074107417,\n",
       " -0.0060037244158897074,\n",
       " -0.015532873583233507,\n",
       " 0.0029444182314970293,\n",
       " -0.017883155509106134,\n",
       " -0.02585310863517951,\n",
       " -0.021480795013053163,\n",
       " -0.0019005776863711807,\n",
       " -0.018539659693634258,\n",
       " -0.02249181086118002,\n",
       " 0.009026923224035917,\n",
       " -3.872345135619523e-06,\n",
       " -0.01717413218190866,\n",
       " -0.002658839339635681,\n",
       " -0.011173689746774499,\n",
       " 0.02717924492725794,\n",
       " 0.02299075389240978,\n",
       " 0.011981189260444738,\n",
       " 0.012723037983133133,\n",
       " 0.015191491705302108,\n",
       " -0.028728593163616572,\n",
       " 0.017633683993491255,\n",
       " -0.006180980713350363,\n",
       " -0.0040965820695155015,\n",
       " 0.018487138688319752,\n",
       " 0.0009223874083582259,\n",
       " -0.004605371974334477,\n",
       " -0.016530757783047877,\n",
       " 0.02917501705217698,\n",
       " 0.011364075364241206,\n",
       " -0.00783208665127602,\n",
       " -0.028781114168931077,\n",
       " 0.016950920237628456,\n",
       " 0.02027282865462593,\n",
       " -0.0050485120194941864,\n",
       " -0.007635135675314356,\n",
       " 0.018881041571565654,\n",
       " -0.025958148783163364,\n",
       " 0.018552789479301595,\n",
       " 0.015165231202644855,\n",
       " -0.018040716662404494,\n",
       " 0.00028332229726126586,\n",
       " 0.014534987520773986,\n",
       " -0.00917791948450061,\n",
       " 0.006647097883427915,\n",
       " -0.00803560298573264,\n",
       " 0.013445192027320522,\n",
       " 0.00879714731824462,\n",
       " 0.0037453526195029545,\n",
       " -0.0034597734948109624,\n",
       " -0.01395726484421762,\n",
       " 0.009309220135141719,\n",
       " -0.0011603699540605583,\n",
       " 0.000993782189531224,\n",
       " 0.03180103006499917,\n",
       " -0.04671679068335172,\n",
       " 0.018618440270283438,\n",
       " 0.023161444831375482,\n",
       " 0.004047343976279119,\n",
       " -0.018487138688319752,\n",
       " -0.01391787455589303,\n",
       " 0.004129406999345135,\n",
       " 0.023200834188377498,\n",
       " -0.014968279761021904,\n",
       " -0.015138970699987604,\n",
       " 0.0006056245188373567,\n",
       " 0.009453650571450166,\n",
       " 0.015900515032499583,\n",
       " 0.010300540373444994,\n",
       " -0.00655846996752823,\n",
       " -0.012512956755842844,\n",
       " -0.004743237983470544,\n",
       " 0.0014434871275246024,\n",
       " 0.024737052639068793,\n",
       " -0.007976518018907043,\n",
       " 0.007221538579228734,\n",
       " -0.0044379639474469,\n",
       " -0.01834270732068873,\n",
       " -0.028203390561052137,\n",
       " -0.02358160542331091,\n",
       " -0.009827857844872487,\n",
       " -0.007713916251963537,\n",
       " -0.021822176890984563,\n",
       " -0.01976075583772883,\n",
       " 0.004378878514960015,\n",
       " 0.0001998232620955465,\n",
       " 0.020824290828525042,\n",
       " 0.023227093759712172,\n",
       " -0.019944576562361867,\n",
       " 0.023227093759712172,\n",
       " 0.015047060337671085,\n",
       " -0.01609746554279996,\n",
       " 0.012959379713080676,\n",
       " -0.005156835079556167,\n",
       " 0.028886154316914936,\n",
       " -0.02233424970788166,\n",
       " 0.015112711128652928,\n",
       " -0.009755642161056975,\n",
       " -0.01918303222984989,\n",
       " 0.004162232394836055,\n",
       " 0.0075432253129978375,\n",
       " -0.018881041571565654,\n",
       " 0.0071887136493991,\n",
       " 0.02035160923127511,\n",
       " -0.0007779566810114736,\n",
       " -0.006417321977636618,\n",
       " 0.009867248133197077,\n",
       " 0.03258883583149097,\n",
       " 0.010582836353228221,\n",
       " 0.005275005944529937,\n",
       " -0.008764321922753698,\n",
       " -0.01865782962728545,\n",
       " 0.012355396533867058,\n",
       " -0.010412145414262521,\n",
       " 0.007326579192873879,\n",
       " 0.010234889582463153,\n",
       " -0.010609096855885472,\n",
       " 0.026483351385727803,\n",
       " -0.006473124498045381,\n",
       " 0.0016404381034862664,\n",
       " -0.0043362057802185895,\n",
       " -0.0234240461326577,\n",
       " 0.014666288171415095,\n",
       " 0.0029870909662384542,\n",
       " -0.015099580411663014,\n",
       " 0.013156330223381052,\n",
       " -0.02725802550390712,\n",
       " -0.021638356166351524,\n",
       " -0.015112711128652928,\n",
       " -0.01591364481816692,\n",
       " 0.009886942811698083,\n",
       " -0.0010815894938266996,\n",
       " -0.020627340318224666,\n",
       " 0.00842950493765597,\n",
       " 0.020404128373944463,\n",
       " -0.004447811286697404,\n",
       " -0.005462109115579809,\n",
       " 0.0048088883087910985,\n",
       " -0.0159924253948161,\n",
       " 0.0019809992533981347,\n",
       " -0.0022403183410941627,\n",
       " -0.030041601532672817,\n",
       " -0.011652937168180676,\n",
       " -0.005885554016577224,\n",
       " 0.032457534249527284,\n",
       " 0.011062083774634397,\n",
       " -0.018066976233739172,\n",
       " -0.013130070652046374,\n",
       " -0.00013150586174982235,\n",
       " -0.03311403843405541,\n",
       " -0.014850109827370709,\n",
       " -0.009821292952038816,\n",
       " -0.003574661680537255,\n",
       " -0.003755200191584102,\n",
       " 0.0029591897060340724,\n",
       " -0.0037650477636652496,\n",
       " 0.014246126648157092,\n",
       " 0.013825964193576512,\n",
       " 0.005022251982498223,\n",
       " -0.02623387987011292,\n",
       " -0.018565919264968932,\n",
       " 0.011731717744829857,\n",
       " -0.002118865029703557,\n",
       " 0.010674746715544739,\n",
       " -0.0046283495649136076,\n",
       " -0.03487346696638176,\n",
       " -0.002328946256993847,\n",
       " -3.882602689722661e-05,\n",
       " 0.009197614163001617,\n",
       " -0.004372313622126345,\n",
       " 0.013812833476586598,\n",
       " -0.015467222792251665,\n",
       " -0.01783063636643678,\n",
       " -0.00677511608765219,\n",
       " 0.008902187466228477,\n",
       " -0.013523972603969703,\n",
       " -0.00846889522598056,\n",
       " 0.01825079695837221,\n",
       " -0.01429864672214902,\n",
       " -0.00265719788359662,\n",
       " -0.007681091322133904,\n",
       " -0.022741282376794902,\n",
       " -0.009952593602679926,\n",
       " -0.0036468771315221224,\n",
       " 0.029805259802725276,\n",
       " 0.0014426665159203939,\n",
       " 0.012027144441602997,\n",
       " -0.0033235489417139576,\n",
       " -0.021218193711770944,\n",
       " 8.780734795122142e-05,\n",
       " -0.022701891157147738,\n",
       " 0.008061863488389893,\n",
       " -0.00401780149286632,\n",
       " -0.014653158385747758,\n",
       " 0.016583278788362382,\n",
       " 0.007661396177971609,\n",
       " -0.0014451283507330198,\n",
       " -0.012900293814932502,\n",
       " 0.011961493650621154,\n",
       " 0.01739734226354371,\n",
       " 0.004854843489949357,\n",
       " -0.0027277721113730703,\n",
       " -0.02707420477927408,\n",
       " -0.00022074930911223937,\n",
       " -0.022216079774230464,\n",
       " -0.0017266041845733248,\n",
       " -0.019393114388462755,\n",
       " -0.009847552523373493,\n",
       " -0.024947132935036507,\n",
       " -0.010871698157167691,\n",
       " -0.02057481931291016,\n",
       " 0.012663953016307536,\n",
       " -0.003883218395808377,\n",
       " -0.0087052369559281,\n",
       " 0.0002211596149143437,\n",
       " -0.009374869994800986,\n",
       " -0.015900515032499583,\n",
       " 0.0014434871275246024,\n",
       " -0.016924660666293778,\n",
       " 0.005156835079556167,\n",
       " -0.007136193109745884,\n",
       " 0.01783063636643678,\n",
       " 0.008803712211078289,\n",
       " -0.007864912046766941,\n",
       " -0.017371082692209036,\n",
       " 0.009407695390291907,\n",
       " 0.002420856619310366,\n",
       " -0.031118266309136368,\n",
       " 0.021743396314335382,\n",
       " 0.2241565586913528,\n",
       " -0.017449863268858216,\n",
       " 0.015257141564961375,\n",
       " 0.034610863802454386,\n",
       " 0.036291513620776705,\n",
       " 0.021507054584387838,\n",
       " 0.007425054913685354,\n",
       " -0.0036534420243557915,\n",
       " 0.005846163728252633,\n",
       " 0.009808162235048903,\n",
       " -0.020627340318224666,\n",
       " 0.002783574864612477,\n",
       " -0.01941937395979743,\n",
       " 0.00030835150416240866,\n",
       " 0.014062304992201478,\n",
       " 0.009959158495513595,\n",
       " -0.004625067118496772,\n",
       " -0.00874462724425269,\n",
       " -0.02809835041306828,\n",
       " -0.0014746710669764625,\n",
       " -0.011442855940890386,\n",
       " -0.010911088445492281,\n",
       " -0.015165231202644855,\n",
       " 0.0027605972740333477,\n",
       " 0.015506613080576255,\n",
       " -0.0117973685358117,\n",
       " -0.01651762799738054,\n",
       " -0.00710336817991625,\n",
       " 0.015309661638953304,\n",
       " -0.010385885842927845,\n",
       " -0.010720702828025574,\n",
       " 0.002049932257966168,\n",
       " -0.0010643563008923523,\n",
       " 0.017266042544225178,\n",
       " 0.011705457242172606,\n",
       " 0.007247798616224698,\n",
       " 0.02661465296769149,\n",
       " -0.0010971814635526297,\n",
       " 0.026942905059955547,\n",
       " -0.004467506430859699,\n",
       " -0.00456926459808801,\n",
       " -0.0018808825422088856,\n",
       " -0.011226209820766428,\n",
       " -0.039127610654856905,\n",
       " 0.01353710238963704,\n",
       " 0.0030691539893044693,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"Hello sot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8816879297904884\n",
      "0.7611042394113705\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "vector1 = embeddings.embed_query(\"artificial intelligence\")\n",
    "vector2 = embeddings.embed_query(\"machine learning\")\n",
    "\n",
    "print(cosine_similarity(vector1, vector2))\n",
    "\n",
    "vector3 = embeddings.embed_query(\"toyota corolla\")\n",
    "\n",
    "print(cosine_similarity(vector1, vector3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pinecone Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone as Pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "pinecone_client = Pinecone(\n",
    "   api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "   environment=os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    ")\n",
    "\n",
    "vecdb = Pinecone.from_existing_index(\n",
    "    index_name=\"sot-demo\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗ †\\nUniversity of Toronto' metadata={'source': './papers/1706.03762.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = \"./papers/1706.03762.pdf\"\n",
    "\n",
    "# Initialize PDF loader\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# Load and split text\n",
    "data = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "len(data)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bec15916-24c8-4eb1-8a85-0608970642d8',\n",
       " '7301accb-644c-4300-aae2-19056b469990',\n",
       " '1d93bbc3-54d9-4782-9064-3a2c5b62d241',\n",
       " 'a6480977-66cc-4033-ac76-8d80959766f0',\n",
       " 'ea8ecb28-a0ba-4d66-b6d2-31128a30367f',\n",
       " '75036440-b147-420c-9547-d31e802f7cc9',\n",
       " '704b9d9c-915b-4872-a848-b3f8955924a9',\n",
       " '2c6b9168-a758-4ba4-97f6-19a08d324d98',\n",
       " 'f5bb1ccd-2369-48e4-b68c-973c0633d2d6',\n",
       " '0dbea2fb-f8b2-4f08-ab06-eded51493a43',\n",
       " '23630fda-84b8-4c41-8ac7-a2751e29d584',\n",
       " '30268865-ea9c-4c88-b908-cd4ffd220fe6',\n",
       " '016ce368-2f7a-4e09-8df0-13a485bb2ebe',\n",
       " '753cb8aa-4dc5-45f2-b015-c154d8cd3fec',\n",
       " 'b68e190c-1418-4930-8e06-9b4901197cf6',\n",
       " '98e570ff-fd35-4461-af61-ca82d44f41c1',\n",
       " '56e245de-89a0-4d37-ad8d-75ace610c5f7',\n",
       " '6de43cb4-e6dc-4603-ab4f-9b326f8375ab',\n",
       " '0583a451-600d-4290-9b2c-784bb7537304',\n",
       " 'b74d5a66-4952-4779-a725-71136d99a770',\n",
       " 'e934fe94-bfa9-4a52-8821-2ab236621caa',\n",
       " '0e65090b-4bd6-4c95-bc74-7b98529d70b1',\n",
       " 'b0fa151e-3b2c-4d27-8f53-a0098bffb6e7',\n",
       " 'b03a3d05-a661-49e8-b7b5-609a699c8f8c',\n",
       " '5656b088-c587-4e88-bd66-5fb84e7edcb0',\n",
       " '458bf811-4b3a-46fb-8362-93e9c5ef4f39',\n",
       " '02a128c5-580f-49be-93c2-8dc32e2908df',\n",
       " 'ac435474-7ee6-42bf-94db-22cdf7ce7321',\n",
       " 'f843f6d7-0469-470b-93ae-0788697f8104',\n",
       " '9f6d5697-cbde-4acd-bb98-77352adab8ca',\n",
       " '148e34b3-2118-4998-b2bc-c181ab932044',\n",
       " '30c45abe-26ef-4f34-bca7-d1400903e87f',\n",
       " 'aa1fe0c0-9aef-49c1-8325-8c5397069227',\n",
       " '7eef0bb4-5dff-4655-8c36-308571d70907',\n",
       " '044679e5-5c0e-4aff-bf42-6e42ffd69fac',\n",
       " '0edef03c-9420-4cb0-ba6d-57d11a3971d8',\n",
       " '6c60d47f-fa56-42de-b261-544f300b8029',\n",
       " 'acd97eda-4e2f-4eeb-816b-d0702ad9ab28',\n",
       " '0bca1bff-ff58-4b65-bad3-e9a3c5276ea4',\n",
       " '7cd08730-e705-4e1e-9221-9bedb1fc4d89',\n",
       " '6ed0524e-8828-4d76-97d9-67e48aafc2b7',\n",
       " '59261167-24de-4280-a762-d3720360fd7b',\n",
       " '1e91e716-01bf-4489-9280-9a639c2c1989',\n",
       " '1f93b0ed-f57b-4d22-8d35-12095ab817b8',\n",
       " 'bc0e050b-e12c-40af-a560-91ec2f6a50dc',\n",
       " '8aa7c85b-6569-4719-ada1-233649ae6306',\n",
       " '5cb34df1-1952-4c3e-897f-7a756d251f65',\n",
       " 'a05fa842-fee8-470b-b9b3-f07c3c46210d',\n",
       " 'efe1e196-a0f8-41f3-9552-22f6e539c5c7',\n",
       " 'fd7d2002-5df9-44cb-8c03-d2592483c720',\n",
       " '1492ba4e-dc7f-4b52-815a-fb77b97f4144',\n",
       " 'dc47d425-85d1-439c-8f6a-fbc45cdd5441',\n",
       " '05750cd9-0e48-4062-81fe-866961470bcd',\n",
       " '7ac30164-2c1c-4c65-9614-555aae88d0ba',\n",
       " 'f5b9fba9-9964-4751-9d9d-f3b0a2251bae',\n",
       " '832cfbca-cede-49f1-aba6-1d53757335a9',\n",
       " 'e1a4a457-96c4-410f-b54a-56a8dc1fba64',\n",
       " '37655560-3b73-43db-9f6d-62365c49526b',\n",
       " '7dae52ce-1c4c-4640-bd92-337083eff7b9',\n",
       " 'da71dce6-ea4d-4f62-b8c9-283eac9aaa05',\n",
       " '691259b2-c723-4dc1-808b-6e4b16cab271',\n",
       " 'cc4d2c3d-fb8e-489f-a75a-009cbace11d4',\n",
       " 'ad0fc8c9-1220-48e8-8a5d-0fc1866ab3b5',\n",
       " 'dd23be4a-644b-40a1-bac3-3ea1b899830d',\n",
       " '25469658-59ad-4551-b6aa-47085cdd0d3f',\n",
       " '51f56b57-d53f-4a9b-aaef-7dd8821aa322',\n",
       " '505b298c-b3cb-42cc-82af-5d4f19379595',\n",
       " '51130d2b-cd23-4c4c-a4cd-91a9c3ec1714',\n",
       " '7c52bb36-1222-4de7-899c-11f61cc63b86',\n",
       " '0d140a48-5b78-4d1c-a6ce-da846b781102',\n",
       " 'd26273d8-72be-47d8-b15b-30100c15d21f',\n",
       " '6885bae8-8d47-4d57-be2d-dacf13be6f30',\n",
       " 'aca108c1-015d-4393-bc8d-0164743bbd63',\n",
       " '70d0d968-b763-4d0a-beac-613b95ac834d',\n",
       " 'd722e97b-7612-4e27-bcea-432dca1b9b07',\n",
       " '908d3de1-7dcd-4f81-b93b-ea3c0273f6ef',\n",
       " '38a26ace-c7da-4eeb-be28-46715d65c3da',\n",
       " '520c7c1e-cceb-4784-a5d7-54f4d59d06e8',\n",
       " '2c36de40-7a00-4502-9e3d-fb1686e62654',\n",
       " '6bf37a79-92f4-4986-bde6-e9ad77d51059',\n",
       " 'e42955c6-de67-4c03-8fa7-46a074c57f37',\n",
       " '4a35d43d-f280-4bfe-9244-3f45cdfce54c',\n",
       " 'a7478609-1ebc-4b35-b0e7-960296394466',\n",
       " 'cc0f37ce-28eb-40ad-8ae9-bf0e68d8655e',\n",
       " '60277575-0a0f-47f3-8e60-0c0bbb205dae',\n",
       " '7391284a-8956-4812-91c0-06903c102ae5',\n",
       " 'f3c229d9-1187-440b-8603-65482f512b39',\n",
       " '98f64cad-a8e6-4eb7-9b3c-f4158aa398d7',\n",
       " 'ac589067-b784-43dd-a449-5506116df440',\n",
       " 'a21e064d-0ef6-4db0-8050-265659e3722a',\n",
       " '77204f54-c5b0-4cd1-976c-d44429b6499d',\n",
       " 'ca84bcb4-0f2e-497f-9d98-c93e01884234',\n",
       " 'be024243-dd03-4433-af97-b89985c37c0c',\n",
       " '48096949-975f-40a2-8252-82a48c1fcbbb',\n",
       " '71323e27-5c27-4e14-ace1-92efced613f0',\n",
       " '9e4ada14-f518-46a1-a84e-e5d5b5f1b1ba',\n",
       " 'fa34ff3b-182b-4f30-934f-e3f5f1ee1ba4',\n",
       " 'ade122b2-e4cc-4d40-aac6-9d09080d530b',\n",
       " 'b2d063ad-bed3-4b00-b0db-e165941df1f4',\n",
       " '8be03bc3-420a-4047-8a82-ebc515bc08d0',\n",
       " 'bf11ede8-979a-4ec5-b477-32e70ed906e0',\n",
       " 'fe24827f-d7dc-438b-adca-8fc72d6a02f0',\n",
       " '628708e5-31fa-4250-aa31-81636b77be3d']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecdb.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is a transformer?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is a transformer?\",\n",
      "  \"context\": \"To the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\\n\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\n\\nIn contrast to RNN sequence-to-sequence models [ 37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\\n\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\n\\nIn contrast to RNN sequence-to-sequence models [ 37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nHuman: What is a transformer?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:ChatOpenAI] [1.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-7ee1e3b8-dbd5-4b65-abe9-31486dfb5afd-0\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 78,\n",
      "      \"prompt_tokens\": 417,\n",
      "      \"total_tokens\": 495\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_b28b39ffa8\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [1.73s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [1.74s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [2.81s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is a transformer?',\n",
       " 'result': 'A transformer is a model architecture for neural sequence transduction that relies entirely on self-attention to compute representations of its input and output without using traditional sequence-aligned RNNs or convolution. The Transformer model allows for more parallelization and has been shown to achieve state-of-the-art results in tasks such as translation, with significantly faster training times compared to models based on recurrent or convolutional layers.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    retriever=vecdb.as_retriever(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.invoke(\"What is a transformer?\", callback_handler=StdOutCallbackHandler())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
