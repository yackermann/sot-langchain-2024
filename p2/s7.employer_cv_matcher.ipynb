{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employer scrapper\n",
    "\n",
    "1. Download the website using `requests`\n",
    "2. Extract the text from the website using `BeautifulSoup`\n",
    "3. Split text and save it to the vector db\n",
    "4. Chat with the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings \n",
    "\n",
    "# ----- OpenAI ----- #\n",
    "chat_model = ChatOpenAI(name=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----- Ollama ----- #\n",
    "# chat_model = ChatOllama()\n",
    "# embeddings = OllamaEmbeddings()\n",
    "\n",
    "\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vecdb = Chroma(\n",
    "    collection_name=\"website_sum\",\n",
    "    embedding_function=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getWebsiteAndRelatedLinks(website_url):\n",
    "    response = requests.get(\n",
    "        website_url,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-GB,en;q=0.6',\n",
    "            'Sec-Ch-Ua': '\"Google Chrome\";v=\"128\", \"Chromium\";v=\"128\", \";Not A Brand\";v=\"99\"',\n",
    "            'Sec-Ch-Ua-Mobile': '?0',\n",
    "            'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
    "            'Sec-Ch-Ua-Arch': '\"x86\"',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "    )\n",
    "\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract the host from the URL\n",
    "    parsed_url = urlparse(website_url)\n",
    "    host = parsed_url.netloc\n",
    "    host = host.replace('www.', '')\n",
    "    \n",
    "    # Get all the links\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href') is not None and host in link.get('href'):\n",
    "            links.append(link.get('href'))\n",
    "\n",
    "    # Filter out the links that are not valid\n",
    "    links = [link for link in links if link is not None]\n",
    "\n",
    "    # Filter sign in and sign up links\n",
    "    links = [link for link in links if 'sign' not in link and 'login' not in link]\n",
    "\n",
    "    unduplicated_links = []\n",
    "    for link in links:\n",
    "        if link not in unduplicated_links:\n",
    "            unduplicated_links.append(link)\n",
    "\n",
    "    links = unduplicated_links\n",
    "\n",
    "    text = soup.get_text() \n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # Be nice to the server xoxo\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    return text, links, host\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "def summarizePages(website_pages):\n",
    "    prompt_template = \"\"\"Write a concise summary of the following:\n",
    "    \"{text}\"\n",
    "    CONCISE SUMMARY:\"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Define LLM chain\n",
    "    llm_chain = LLMChain(llm=chat_model, prompt=prompt)\n",
    "\n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "    return stuff_chain.run(website_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get broader site information\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def summarizeWebsiteExpanded(website_url):\n",
    "    website_text, website_links, website_host = getWebsiteAndRelatedLinks(website_url)\n",
    "\n",
    "    website_pages = [\n",
    "        Document(page_content=website_text, id=website_url, metadata={'url': website_url})\n",
    "    ]\n",
    "\n",
    "    for link in website_links:\n",
    "        try:\n",
    "            text, links, host = getWebsiteAndRelatedLinks(link)\n",
    "            website_pages.append(Document(page_content=text, id=link, metadata={'url': link}))\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting link: {link}\")\n",
    "            print(e)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for website_page in website_pages:\n",
    "        print(website_page, website_page.id)\n",
    "        website_summary = summarizePages([website_page])\n",
    "        summaries.append(Document(page_content=website_summary, id=website_page.id, metadata=website_page.metadata))\n",
    "    \n",
    "    return summaries\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def summarizeAndSave(website_url: str):\n",
    "    \"\"\"Takes a website URL and returns a summary of the website and saves the summaries of the individual pages\"\"\"\n",
    "    summaries = summarizeWebsiteExpanded(website_url)\n",
    "\n",
    "    vecdb.add_documents(summaries)\n",
    "\n",
    "    return summarizePages(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "@tool\n",
    "def processPDF(file_path: str):\n",
    "    \"\"\"Takes a PDF location and returns a summary of the PDF\"\"\"\n",
    "    # Initialize PDF loader\n",
    "    loader = PyPDFLoader(file_path)\n",
    "\n",
    "    # Initialize text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "    )\n",
    "\n",
    "    # Load and split text\n",
    "    data = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "    vecdb.add_documents(data)\n",
    "\n",
    "    return summarizePages(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "vecdb_tool = create_retriever_tool(\n",
    "    vecdb.as_retriever(),\n",
    "    \"search_vecdb\",\n",
    "    \"Retrieve documents from the VecDB\",\n",
    ")\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = load_tools([], llm=chat_model)\n",
    "tools.append(vecdb_tool)\n",
    "tools.append(summarizeAndSave)\n",
    "tools.append(search)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    chat_model,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "def call_agent(user_question):\n",
    "    response = agent.run(input=user_question)\n",
    "    return response\n",
    "\n",
    "def add_message(history, message):\n",
    "    print(message)\n",
    "    for x in message[\"files\"]:\n",
    "        result = processPDF(x)\n",
    "        history.append(((x,), result))\n",
    "        \n",
    "    if message[\"text\"] is not None:\n",
    "        history.append((message[\"text\"], None))\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "def bot(history):\n",
    "    history[-1][1] = call_agent(history[-1][0])\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "with gr.Blocks(fill_height=True) as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        elem_id=\"chatbot\",\n",
    "        bubble_full_width=False,\n",
    "        scale=1,\n",
    "    )\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(interactive=True,\n",
    "                                      file_count=\"multiple\",\n",
    "                                      placeholder=\"Enter message or upload file...\", show_label=False)\n",
    "\n",
    "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
