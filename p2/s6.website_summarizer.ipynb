{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building website summarizer\n",
    "\n",
    "1. Download the website using `requests`\n",
    "2. Extract the text from the website using `BeautifulSoup`\n",
    "3. Split text and save it to the vector db\n",
    "4. Chat with the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings \n",
    "\n",
    "# ----- OpenAI ----- #\n",
    "chat_model = ChatOpenAI(name=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----- Ollama ----- #\n",
    "# chat_model = ChatOllama()\n",
    "# embeddings = OllamaEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getWebsiteAndRelatedLinks(website_url):\n",
    "    response = requests.get(\n",
    "        website_url,\n",
    "        headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-GB,en;q=0.6',\n",
    "            'Sec-Ch-Ua': '\"Google Chrome\";v=\"128\", \"Chromium\";v=\"128\", \";Not A Brand\";v=\"99\"',\n",
    "            'Sec-Ch-Ua-Mobile': '?0',\n",
    "            'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
    "            'Sec-Ch-Ua-Arch': '\"x86\"',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "    )\n",
    "\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract the host from the URL\n",
    "    parsed_url = urlparse(website_url)\n",
    "    host = parsed_url.netloc\n",
    "    host = host.replace('www.', '')\n",
    "    \n",
    "    # Get all the links\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.get('href') is not None and host in link.get('href'):\n",
    "            links.append(link.get('href'))\n",
    "\n",
    "    # Filter out the links that are not valid\n",
    "    links = [link for link in links if link is not None]\n",
    "\n",
    "    # Filter sign in and sign up links\n",
    "    links = [link for link in links if 'sign' not in link and 'login' not in link]\n",
    "\n",
    "    unduplicated_links = []\n",
    "    for link in links:\n",
    "        if link not in unduplicated_links:\n",
    "            unduplicated_links.append(link)\n",
    "\n",
    "    links = unduplicated_links\n",
    "\n",
    "    text = soup.get_text() \n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # Be nice to the server xoxo\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    return text, links, host\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = \"https://kpmg.com/nz/en/home.html\"\n",
    "website_text, website_links, website_host = getWebsiteAndRelatedLinks(website_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get broader site information\n",
    "from langchain.docstore.document import Document\n",
    "website_pages = [\n",
    "    Document(page_content=website_text, id=website_url, metadata={'url': website_url})\n",
    "]\n",
    "\n",
    "for link in website_links:\n",
    "    try:\n",
    "        text, links, host = getWebsiteAndRelatedLinks(link)\n",
    "        website_pages.append(Document(page_content=text, id=link, metadata={'url': link}))\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting link: {link}\")\n",
    "        print(e)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(website_pages)\n",
    "print( len(website_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "def summarizePages(website_pages):\n",
    "    prompt_template = \"\"\"Write a concise summary of the following:\n",
    "    \"{text}\"\n",
    "    CONCISE SUMMARY:\"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    # Define LLM chain\n",
    "    llm_chain = LLMChain(llm=chat_model, prompt=prompt)\n",
    "\n",
    "    # Define StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "    return stuff_chain.run(website_pages)\n",
    "\n",
    "summaries = []\n",
    "\n",
    "for website_page in website_pages:\n",
    "    website_summary = summarizePages([website_page])\n",
    "    summaries.append(Document(page_content=website_summary, id=website_page.id, metadata=website_page.metadata))\n",
    "\n",
    "print(summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vecdb = Chroma(\n",
    "    collection_name=\"vdb-\" + website_host,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma.vdb\",  # Where to save data locally, remove if not neccesary\n",
    ")\n",
    "\n",
    "vecdb.add_documents(summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    retriever=vecdb.as_retriever(),\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me about BMW?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradIO Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "vecdb_tool = create_retriever_tool(\n",
    "    vecdb.as_retriever(),\n",
    "    \"search_vecdb\",\n",
    "    \"Searches the vector database for similar questions and returns the most similar texts.\",\n",
    ")\n",
    "\n",
    "tools = load_tools([], llm=chat_model)\n",
    "tools.append(vecdb_tool)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    chat_model,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "def call_agent(user_question):\n",
    "    response = agent.run(input=user_question)\n",
    "    return response\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    title = gr.HTML(\"<h1>The Data Moves Me Chatbot</h1>\")\n",
    "    input = gr.Textbox(label=\"What would you like to know?\")\n",
    "    output = gr.Textbox(label=\"Answer\")\n",
    "    btn = gr.Button(\"Ask\")\n",
    "    btn.click(fn=call_agent, inputs=input, outputs=output)\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
